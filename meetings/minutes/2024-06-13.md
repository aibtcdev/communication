## AIBTCdev Thursday, June 13

### Working Group Updates

Reviewed our repositories, communication repo.

### Development Updates

Reviewed the [project board](https://github.com/orgs/aibtcdev/projects/3/views/1)

### Demo Time

Luigi shared presentation slides on RAG

- example of how answers are provided in prompts
- chunking and content considerations
- details and information on chunking process

### Latest AI News

[Apple Intelligence](https://machinelearning.apple.com/research/introducing-apple-foundation-models) - AI redefined!

- small model on-device [with unique strategies](https://x.com/rohanpaul_ai/status/1800521425683636454)
- [secure and private cloud compute](https://petapixel.com/2024/06/10/apple-intelligence-brings-private-secure-ai-to-entire-apple-ecosystem/) for larger queries
- OpenAI as an optional third layer

AI agents are [learning from each other](https://the-decoder.com/artificial-generational-intelligence-ai-agents-learn-from-each-other-across-generations/)

- Oxford / Google have developed reinforcement learning models
- "in-context" for learning quickly and adapting to new environments
- "in-weights" for accumulating knowledge over generations
- another collaboration themed paper: [mixture of agents](https://x.com/rohanpaul_ai/status/1800298331773567412)

Is matrix multiplication [necessary for LLMs](https://x.com/rohanpaul_ai/status/1799122826114330866)?

- great [visual breakdown of matrix multiplication](https://x.com/svpino/status/1800151091461652740?t=-E2sMrLnukxxTnzcSCKDyg&s=09)
- uses ternary accumulations for the weights
- weights contrained to `{-1, 0, +1}`
- related [arxiv paper](https://arxiv.org/abs/2406.02528) and [github](https://github.com/ridgerchu/matmulfreellm)

PowerInfer-2 is a [fast inference engine for mobile](https://x.com/hodlenx/status/1800788808272937297)

- runs a 47B model with 29x speedup on smartphones
- achieves 11 tokens/second, [technical details here](https://powerinfer.ai/v2/)

Union Square Ventures: [Collision Course](https://blog.usv.com/collision-course)

- AI and web3 are intertwined, how they're approaching investments
- user-controlled identities and data pave the way for personalized AI applications
- AI-driven agents can become increasingly effective by accessing and learning from user-controlled data

New tools

- [code2prompt](https://github.com/mufeedvh/code2prompt): convert codebase into an LLM prompt
- [caret](https://github.com/jcollingj/caret): an Obsidian plugin for branching conversations
- [WebRTC AI Voice Chat](https://github.com/lalanikarim/webrtc-ai-voice-chat): LangChain example of speech input/output with related models

New models

- Google [released PH-LLM](https://arxiv.org/pdf/2406.06474v1): a version of Gemini fine-tuned for [personal health and wellness](https://x.com/shreyjaineth/status/1800586918117453911?t=Gtbe5opPJ0XY_Y1F2uPwTg&s=09)
- Abacus AI released [Smaug-32k](https://x.com/bindureddy/status/1800675497023840690?t=a6MaVaLRoYKYN6NvGepa2Q&s=09): improves upon Llama-3 70B with extended context and better reasoning
- Tess released [Tess-v2.5](https://x.com/migtissera/status/1800983129827774551): based on Qwen2-72B, ranks very well across evaluations
- CognitiveComputations released several Dolphin fine-tunes, with [dolphin-2.9.2-qwen2-72b](https://x.com/psyv282j9d/status/1800611992991904007?t=FGowuwyly4quowhBZ3Hk9w&s=09) performing very well in real-world tests
