## AIBTCdev Thursday, Apr 18

Video + Recap: Thursday, Apr 18
(link will be posted once uploaded)

### Working Group Updates

Great weather, Bitcoin halving, Nakamoto release!

Owe some recordings and meeting updates, will get those caught up!

Great area to help out if anyone feels inclined, can use AI in the process too.

Round table:

- quick intro, who you are
- how are you using AI today
- what are you most excited about?
- do you have any blockers?

Signal21 to help with dashboards

- evaluating use case for resource contract as well

### Latest AI News

Open weight models [doing well in leaderboards](https://chat.lmsys.org/?leaderboard)

- OpenAI GPT4/Claude Opus/Google Bard on top still
- Cohere Command R Plus / Mistral Medium very close to GPT4, very large though
- Qwen / WizardLM both good too, some smaller options
- Lots of fine-tunes coming up as base models are updated

Sometimes a larger parameter with model performs better than smaller ones even when quantized, so getting the balance right is important!

Anyone have any open source or open weight LLMs they prefer to use?

New [snowflake-arctic-embed models](https://www.snowflake.com/blog/introducing-snowflake-arctic-embed-snowflakes-state-of-the-art-text-embedding-family-of-models/) now open source

- embeddings are vector representations of data that help LLMs understand natural language
- default is often OpenAI whein working with APIs, lots of options out there
- another variable that can greatly affect an LLMs performance
- [not ranked yet](https://huggingface.co/spaces/mteb/leaderboard) on the leaderboard but lots of articles saying it performs very well

Preparing data for LLM usage is another growing sector:

- [Jina AI open-sourced reader](https://github.com/jina-ai/reader/), a tool to convert any URL into LLM-friendly input
- [FireCrawl](https://www.firecrawl.dev/) released recently too, converts any URL into clean markdown for LLMs
- [github2file](https://github.com/cognitivecomputations/github2file) an earlier solution from Eric Hartford for turning Python/Go repos into a prompt

[Interview with Dario Amodei (CEO of Anthropic)](https://www.nytimes.com/2024/04/12/podcasts/transcript-ezra-klein-interviews-dario-amodei.html) in NYTimes

- LLM improvements are incremental but public support has spikes based on big breakthroughs
- focus on "exponential capabilities curve" instead of AGI, models will surpass humans on certain subjects
- large models are nearly as persuasive as humans in changing minds on issues
- [scaling is a challenge](https://arxiv.org/abs/2001.08361), more parameters, more compute, more requirements

Big LLMs and closed source models get bigger and more powerful, but come with a high cost and underlying technology can change quickly.

- developing a "ChatGPT Wrapper" is dangerous
- need to consider things at a lower level (and we are!)

### Development Updates

Let's sort out what we want to build next:

- We have agents that can interact with wallets.
- We have a resource contract that works as a standalone option.
- We have the revenue sharing idea that bolts onto the resource contract.
- We can bolt other things onto the resource contract.
- what happens after a payment is made?

### Available Tasks

Let's focus on creating an agent that deploys a contract.

We can keep it simple, starting with a resource contract.

### Meeting Notes

Key Discussion Points
_(generated with Claude Opus 2024/05/02)_

- Signal21
  - Leveraging AI with their data
  - Creating automation, agents, and solutions
  - Improving efficiency and solving user problems
  - Learning about possibilities and understanding user activity
- Louis (Senior Marketing Analyst at Finance Network)
  - Involved in dev team and onboarding, recently onboarded Bitcoin
  - Curious about Stacks since day 1
  - Growth hacker and ex-developer
  - Interested in AI note-taker that generates action items
  - Running startups in full automation
- Kevin (Replit Developer Onboarding)
  - Agentic approaches to Bitcoin
  - Rewriting public software interfaces (APIs) for agentic processes
  - Discovering Bitcoin flows for payments
  - Exploring novel opportunities in green field territory
- Luigi (Developer/Technical Person at AECom)
  - Managing AI transition inside the company
  - AECom acquired a CPQ (CRM) company
  - Started Machine Learning 6-7 years ago
  - Knowledgeable about Bitcoin, attending to learn more
- Rapha (Self-taught Clarity Developer)
  - Completed Stacks bootcamp
  - Learning to code and excited to continue the journey
  - Small investor in an AI company
- Christopher Perceptions (CEO of NoCodeClarity)
  - Enabling Bitcoin development through Stacks
  - Automating through artificial intelligence
  - Interested in agents deploying agents
  - Following the rapidly moving OSS world
  - Impressed by Replit's self-healing code tool and its potential with agents
- Hero Gamer
  - Learning and curious about AI's benefits for Stacks/Bitcoin
  - Supporting and connecting people in the Stacks ecosystem
  - Knowledgeable about the community and projects
  - Facilitating small grants from the Stacks Foundation
  - Seeking projects that can be supported by the foundation
- Rus's Insights
  - History of AI, ML, and the industry's ups and downs
  - Skepticism about AI hype, but expects something big to emerge
  - Importance of relational databases in running the world
  - Hardware projects with huge potential for power consumption and capabilities
  - Early stage, but foresees significant benefits
  - Uses AI frequently, always needing specialized applications
  - Challenges in generating domain-specific files and navigating cloud providers
- Luigi's Thoughts on AI Progress
  - Networks distinguishing between objects (e.g., cat or dog)
  - Linear scaling of intelligence with more power and data
  - Models surpassing stoicism with GPT-3.5
  - Uncertainty about the limits of AI capabilities
