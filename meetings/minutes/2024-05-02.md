## AIBTCdev Thursday, May 2

### Working Group Updates

- [meeting minutes](https://github.com/orgs/stacks-network/discussions/534) finally caught up!
- planning to publish faster, lots in motion right now
- presentation at [crewai meetup in SF](https://twitter.com/joaomdmoura/status/1783718120495939862)
- new meeting, new crewai release!
- round table, great to hear from everyone
  - cadence: 1/month? 1/quarter?
  - monthly, next one beginning of June

### Latest AI News

So many new model releases! Once a new foundational model drops be sure to follow the creators you like.

- Llama-3-8B with [1M context window](https://twitter.com/BrianRoemmele/status/1785052732174594479)!
- [Qwen1.5-110B](https://x.com/JustinLin610/status/1785565292518678830)
- [Hermes 2 Pro on Llama-3 8B](https://twitter.com/NousResearch/status/1785779313826308096)
  - (shoutout to Hozz! [70B coming soon)](https://x.com/Teknium1/status/1785785368362848292)
- [Dolphin 2.9](https://huggingface.co/cognitivecomputations) for a few:
  - Dolphin 2.9 in Llama-3 8B and 70B (+ [1M context window](https://twitter.com/erhartford/status/1785435637375750349)!)
  - Dolphin 2.9 in Mixtral 8x22b
- Two new [Llava releases](https://x.com/Gradio/status/1785267410812989920)
  - LLaVa-Llama-3-8B
  - LLaVa-Phi-3 Mini

["More Agents Is All You Need" paper](https://x.com/rohanpaul_ai/status/1785648256493535743) uses multiple LLM agents to improve performance, with accuracy scaling as the number of agents increases.

- CoT-SC generates multiple thought chains from a single LLM using diverse Chain-of-Thought (CoT) prompts and selects the most self-consistent answer through majority voting.
- CoT-SC enhances LLMs' reasoning capabilities by integrating multiple reasoning chains, increasing the likelihood of reaching a correct or rational conclusion.
- The key technique in this paper is a two-phase process: feeding the task query into LLM agents to generate answers, followed by majority voting to determine the final answer.

Very large context window allows for [better LLM performance](https://x.com/emollick/status/1784057905953624462)

- allows for many-shot learning in the prompt
- context window size may be more important than model size
- compute scales heavily when increasing context window size
- makes sense along the lines of self-reflection and other learnings

[Model visualization](https://twitter.com/jannchie/status/1784621770018058651) from lm-sys chat arena data

- shows open source is closing the gap
- also shows big tech companies taking over

[Sailor models](https://twitter.com/sivil_taram/status/1785665722963894740), open source + open pipeline

- name is new to me, anyone heard of it?
- end-to-end processing pipeline for LLM training

Fine-tuning isn't always useful

- we've covered this before
- [Catastrophic forgetting in fine-tuning](https://x.com/rohanpaul_ai/status/1783829588436504924)
- [Fine-tuning and when it's useful (beyond the hype)](https://x.com/itsandrewgao/status/1784681712234143862)

Using collaborative models to [achieve better performance](https://x.com/IntuitMachine/status/1785978124485759111)

- we've covered this idea before
- great to see it playing out!

Are we approaching to the [end of the quantization](https://www.reddit.com/r/LocalLLaMA/comments/1cci5w6/quantizing_llama_3_8b_seems_more_harmful_compared/)?

- Llama 3 exposes some challenges with quantization
- if the model is more 'dense' it seems that the quantization breaks the model
- opposite of how it used to be: larger model quantized was more powerful

New GPT-2 model taking over [lm-sys leaderboards](https://twitter.com/AiBreakfast/status/1785315978655494287)

- could be released by OpenAI
- bringing down size, compute requirements
- lots of [speculation around the model](https://twitter.com/itsandrewgao/status/1785013026636357942)

Luigi: would be great to have a benchmark for switching models

- the more crews we have, the more we can test
- maybe we can link with CrewAI and their test workflow?

### Development Updates

- we want to foster working in public
- we want to make collaboration easy
- each repo in the org is a good place for issues
- issues address individual topics in scope
- we can work on standardizing as we go
  - Invoicing, formats, responses, etc
- we can create a project board at org level

### Meeting Notes

Key Discussion Points
(generated with Claude Opus 2024/05/09)

- Chris' Project Idea
  - Received funding for solo founder project
  - Bringing fuzzing to Clarity contracts
  - Nikos has already fuzzed PoX-4 contracts
- Onboarding Resources for Stacks (Binaya)
  - Difficulty for new users without Stacks to pay gas fees
  - Idea to host a contract that sponsors transactions
  - Help users get their first meme coin
  - Need link from Alex for transaction sponsorship
- Defining Success 12 Months from Now
  - Being ahead of the curve before big statements are made
  - Patrick: Front-running opinion leaders and big names
  - Model provenance on Stacks using hashes on-chain
  - Jason suggests using OpenTimestamps model (create issue)
  - Agents spending money for resources like humans
- Key Metrics to Track (Jason)
  - Number of crews created
  - Number of resources deployed and consumed
  - Total value of resources consumed
  - Number of transactions sent by agents
  - API for accessing leaderboard of resources
- Incentivizing Agent Behavior (Binaya)
  - Imagining 100,000s of agents interacting with each other
  - Difficulty envisioning what behavior to incentivize
  - Focusing on agents with objectives rather than just acting sensible
- Potential for Agents (Patrick)
  - Agents could do anything humans can do on the internet
  - Requires a micro-economy to exist
  - Load agents with Bitcoin and let them operate
- Applying UNIX Philosophy (Jason)
  - Start small, do one thing and do it well
  - Offer functionality as a resource
  - Expect outputs to become inputs for chaining
- Thoughts on AI and Agents
  - Binaya interested in DeFi applications
  - Mike differentiates System 1 vs System 2 thinking
  - Current models are System 1, quick answers
  - Luigi emphasizes importance of stochastic agent outputs
  - Keep things scoped down, merge reality with LLMs
- Standards for Payments and Service Discovery (Dan)
  - Building Boom wallet with focus on payments
  - Potential for default standards on how agents work
  - J2 P2 mentioned QR codes for connecting wallets and payments
  - Lightning invoices, LNURLs, URLs for different functions
  - Define payment types with unique IDs and details
  - Simple standards important for people and agents
  - Create issues for practical steps and POCs
  - Metadata and parsing for contract discovery
  - Look into trait + chainhooks to identify contract types
  - Jason suggests LLMs to help label contracts
